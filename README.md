# T3LAB notes:

## XXX
- [xxxxx](https://site) [_comment_]  


## MXNET
- [School of MXNET-Gluon](https://www.d2l.ai/chapter_computer-vision/rcnn.html) [_good]

## OpenCV Deep Learning
- [All models pre-trained for OpenCV](https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV) [_must to follow]  

## Docker
- [jupyter-docker-Heroku](https://www.codingforentrepreneurs.com/blog/jupyter-production-server-on-docker-heroku) [_good]

## Convert PyTorch Models in Production:
- [PyTorch Production Level Tutorials](https://pytorch.org/tutorials/#production-usage) [_Fantastic_]  
- [The road to 1.0: production ready PyTorch](https://pytorch.org/2018/05/02/road-to-1.0.html)
- [PyTorch 1.0 tracing JIT and LibTorch C++ API to integrate PyTorch into NodeJS](http://blog.christianperone.com/2018/10/pytorch-1-0-tracing-jit-and-libtorch-c-api-to-integrate-pytorch-into-nodejs/) [_Good Article_]
- [Model Serving in PyTorch](https://pytorch.org/blog/model-serving-in-pyorch/)
- [PyTorch Summer Hackathon](https://pytorch.devpost.com/) [_Very Important_]
- [Deploying PyTorch and Building a REST API using Flask](https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html) [_Important_]
- [PyTorch model recognizing hotdogs and not-hotdogs deployed on flask](https://github.com/jaroslaw-weber/hotdog-not-hotdog)
- [Serving PyTorch 1.0 Models as a Web Server in C++ ](https://github.com/Wizaron/pytorch-cpp-inference) [_Useful Example_]
- [PyTorch Internals](http://blog.ezyang.com/2019/05/pytorch-internals/)  [_Interesting & Useful Article_]  
- [Flask application to support pytorch model prediction](https://github.com/craigsidcarlson/PytorchFlaskApp)
- [Serving PyTorch Model on Flask Thread-Safety](https://discuss.pytorch.org/t/serving-pytorch-model-on-flask-thread-safety/13921)
- [Serving PyTorch Models on AWS Lambda with Caffe2 & ONNX](https://machinelearnings.co/serving-pytorch-models-on-aws-lambda-with-caffe2-onnx-7b096806cfac)
- [Serving PyTorch Models on AWS Lambda with Caffe2 & ONNX (Another Version)](https://blog.waya.ai/deploy-deep-machine-learning-in-production-the-pythonic-way-a17105f1540e)
- [EuclidesDB - _multi-model machine learning feature database with PyTorch_](https://euclidesdb.readthedocs.io/en/latest/)
- [EuclidesDB - GitHub](https://github.com/perone/euclidesdb/)
- [WebDNN: Fastest DNN Execution Framework on Web Browser](https://github.com/mil-tokyo/webdnn)
- [FastAI PyTorch Serverless API (with AWS Lambda)](https://github.com/alecrubin/pytorch-serverless/)
- [FastAI PyTorch in Production (discussion)](http://forums.fast.ai/t/fastai-pytorch-in-production/16928)


## Funny Projects:
- [control videogame with hand-code](https://github.com/vietnguyen1991/AirGesture) [_]
- [control videogame with hand-video](https://www.youtube.com/watch?v=TT2Tjd_h9ew) [_]

## START with ONNX Projects:
- [START WITH ONNX](https://github.com/mufajjul/onnx-operationalisation)
- [ONNX RUNTIME](https://cloudblogs.microsoft.com/opensource/2019/05/22/onnx-runtime-machine-learning-inferencing-0-4-release/)
- [ONNX RUNTIME-NOTEBOOK AND TUTORIAL](https://github.com/microsoft/onnxruntime)
- [ONNX RUNTIME-OPENVINO](https://cloudblogs.microsoft.com/opensource/2019/08/26/announcing-onnx-runtime-0-5-edge-hardware-acceleration-support/)
- [ONNX RUNTIME- complete tutorial JETSON NANO+ UP SQUARED](https://channel9.msdn.com/Shows/Internet-of-Things-Show/Train-with-Azure-ML-and-deploy-everywhere-with-ONNX-Runtime) [FANTASTIC]  

## Keras Model from Google:
- [python models for deep learning](https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/tree/master/zoo) [_to must to see_]  

## Acellerate with FPGA:
- [Accelerating Python with FPGAs](https://www.youtube.com/watch?v=b_KXFaFRGRY&t=1326s) [ FPGA ] 

## Project Zoo:
- [Project Zoo](https://modelzoo.co/) [_BEST EVER]  

## OCR - Tesseract
- [Tesseract Open Source OCR Engine (main repository)](https://github.com/tesseract-ocr/tesseract) [_from google] 
- [Tesseract import new fonts](https://github.com/astutejoe/tesseractfonts) [from developer]  

## XXX
- [xxxxx](https://site) [_comment_]  
- [xxxxx](https://site) [_comment_]  
- [xxxxx](https://site) [_comment_]  
- [xxxxx](https://site) [_comment_]  
























